<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model &mdash; pytorch-struct 0.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Networks and Data" href="networks.html" />
    <link rel="prev" title="Torch-Struct: Structured Prediction Library" href="README.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> pytorch-struct
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="README.html">Torch-Struct: Structured Prediction Library</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Chain">Chain</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Hidden-Markov-Model">Hidden Markov Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Semi-Markov">Semi-Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Alignment">Alignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Dependency-Tree">Dependency Tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Non-Projective-Dependency-Tree">Non-Projective Dependency Tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Binary-Labeled-Tree">Binary Labeled Tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Probabilistic-Context-Free-Grammar">Probabilistic Context-Free Grammar</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Autoregressive-/-Beam-Search">Autoregressive / Beam Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Base-Class">Base Class</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="networks.html">Networks and Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="semiring.html">Advanced: Semirings</a></li>
<li class="toctree-l1"><a class="reference internal" href="refs.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pytorch-struct</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/model.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Model">
<h1>Model<a class="headerlink" href="#Model" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch_struct</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Chain">
<h2>Chain<a class="headerlink" href="#Chain" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.LinearChainCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">LinearChainCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#LinearChainCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.LinearChainCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents structured linear-chain CRFs with C classes.</p>
<p>For reference see:</p>
<ul class="simple">
<li><p>An introduction to conditional random fields <span id="id1">[<a class="reference internal" href="refs.html#id11" title="Charles Sutton, Andrew McCallum, and others. An introduction to conditional random fields. Foundations and Trends® in Machine Learning, 4(4):267–373, 2012.">SM+12</a>]</span></p></li>
</ul>
<p>Example application:</p>
<ul class="simple">
<li><p>Bidirectional LSTM-CRF Models for Sequence Tagging <span id="id2">[<a class="reference internal" href="refs.html#id12" title="Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991, 2015.">HXY15</a>]</span></p></li>
</ul>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tensor</em>) – event shape (<em>(N-1) x C x C</em>) e.g.
<span class="math notranslate nohighlight">\(\phi(n,  z_{n+1}, z_{n})\)</span></p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch_shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Compact representation: N long tensor in [0, …, C-1]</p>
<p>Implementation uses linear-scan, forward-pass only.</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(\log(N))\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O(N \log(N) C^2)\)</span></p></li>
</ul>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span>
<span class="k">def</span> <span class="nf">show_chain</span><span class="p">(</span><span class="n">chain</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># batch, N, z_n, z_n_1</span>
<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">LinearChainCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_6_0.png" src="_images/model_6_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_7_0.png" src="_images/model_7_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">event</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">event</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_8_0.png" src="_images/model_8_0.png" />
</div>
</div>
</section>
<section id="Hidden-Markov-Model">
<h2>Hidden Markov Model<a class="headerlink" href="#Hidden-Markov-Model" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.HMM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">HMM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emission</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#HMM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.HMM" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents hidden-markov smoothing with C hidden states.</p>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transition</strong> (<em>tensor</em>) – log-probabilities (<em>C X C</em>) <span class="math notranslate nohighlight">\(p(z_n| z_n-1)\)</span></p></li>
<li><p><strong>emission</strong> (<em>tensor</em>) – log-probabilities (<em>V x C</em>)  <span class="math notranslate nohighlight">\(p(x_n| z_n)\)</span></p></li>
<li><p><strong>init</strong> (<em>tensor</em>) – log-probabilities (<em>C</em>) <span class="math notranslate nohighlight">\(p(z_1)\)</span></p></li>
<li><p><strong>observations</strong> (<em>long tensor</em>) – indices (<em>batch x N</em>) between [0, V-1]</p></li>
</ul>
</dd>
</dl>
<p>Compact representation: N long tensor in [0, …, C-1]</p>
<p>Implemented as a special case of linear chain CRF.</p>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span>

<span class="n">transition</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">emission</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>

<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">HMM</span><span class="p">(</span><span class="n">transition</span><span class="p">,</span> <span class="n">emission</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">observations</span><span class="p">)</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_11_0.png" src="_images/model_11_0.png" />
</div>
</div>
</section>
<section id="Semi-Markov">
<h2>Semi-Markov<a class="headerlink" href="#Semi-Markov" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.SemiMarkovCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">SemiMarkovCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#SemiMarkovCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.SemiMarkovCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents a semi-markov or segmental CRF with C classes of max width K</p>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> – event shape (<em>N x K x C x C</em>) e.g.
<span class="math notranslate nohighlight">\(\phi(n, k, z_{n+1}, z_{n})\)</span></p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Compact representation: N long tensor in [-1, 0, …, C-1]</p>
<p>Implementation uses linear-scan, forward-pass only.</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(\log(N))\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O(N \log(N) C^2 K^2)\)</span></p></li>
</ul>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span>
<span class="k">def</span> <span class="nf">show_sm</span><span class="p">(</span><span class="n">chain</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># batch, N, K, z_n, z_n_1</span>
<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
<span class="n">log_potentials</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1e9</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">SemiMarkovCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_sm</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_14_0.png" src="_images/model_14_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_sm</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_15_0.png" src="_images/model_15_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Use -1 for segments.</span>
<span class="n">event</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">show_sm</span><span class="p">(</span><span class="n">event</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_16_0.png" src="_images/model_16_0.png" />
</div>
</div>
</section>
<section id="Alignment">
<h2>Alignment<a class="headerlink" href="#Alignment" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.AlignmentCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">AlignmentCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_gap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#AlignmentCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.AlignmentCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents basic alignment algorithm, i.e. dynamic-time warping, Needleman-Wunsch, and Smith-Waterman.</p>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tensor</em>) – <dl class="simple">
<dt>event_shape (<em>N x M x 3</em>), e.g.</dt><dd><p><span class="math notranslate nohighlight">\(\phi(i, j, op)\)</span></p>
</dd>
</dl>
<p>Ops are 0 -&gt; j-1, 1-&gt;i-1,j-1, and 2-&gt;i-1</p>
</p></li>
<li><p><strong>local</strong> (<em>bool</em>) – if true computes local alignment (Smith-Waterman), else Needleman-Wunsch</p></li>
<li><p><strong>max_gap</strong> (<em>int</em><em> or </em><em>None</em>) – the maximum gap to allow in the dynamic program</p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Implementation uses convolution and linear-scan. Use max_gap for long sequences.</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(\log (M + N))\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O((M+N)^2)\)</span></p></li>
</ul>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span>
<span class="k">def</span> <span class="nf">show_deps</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">AlignmentCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_deps</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_19_0.png" src="_images/model_19_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_deps</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_20_0.png" src="_images/model_20_0.png" />
</div>
</div>
</section>
<section id="Dependency-Tree">
<h2>Dependency Tree<a class="headerlink" href="#Dependency-Tree" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.DependencyCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">DependencyCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiroot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#DependencyCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.DependencyCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents a projective dependency CRF.</p>
<p>Reference:</p>
<ul class="simple">
<li><p>Bilexical grammars and their cubic-time parsing algorithms <span id="id3">[<a class="reference internal" href="refs.html#id13" title="Jason Eisner. Bilexical grammars and their cubic-time parsing algorithms. In Advances in probabilistic and other parsing technologies, pages 29–61. Springer, 2000.">Eis00</a>]</span></p></li>
</ul>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tensor</em>) – event shape (<em>N x N</em>) head, child or (<em>N x N x L</em>) head,
child, labels with arc scores with root scores on diagonal
e.g. <span class="math notranslate nohighlight">\(\phi(i, j)\)</span> where <span class="math notranslate nohighlight">\(\phi(i, i)\)</span> is (root, i).</p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Compact representation: N long tensor in [0, .. N] (indexing is +1)</p>
<p>Implementation uses linear-scan, forward-pass only.</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(N)\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O(N \log(N) C^2 K^2)\)</span></p></li>
</ul>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
<span class="k">def</span> <span class="nf">show_deps</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">DependencyCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_deps</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_23_0.png" src="_images/model_23_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_deps</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_24_0.png" src="_images/model_24_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Convert from 1-index standard format. (Head is 0)</span>
<span class="n">event</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">show_deps</span><span class="p">(</span><span class="n">event</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_25_0.png" src="_images/model_25_0.png" />
</div>
</div>
</section>
<section id="Non-Projective-Dependency-Tree">
<h2>Non-Projective Dependency Tree<a class="headerlink" href="#Non-Projective-Dependency-Tree" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.NonProjectiveDependencyCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">NonProjectiveDependencyCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiroot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#NonProjectiveDependencyCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.NonProjectiveDependencyCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents a non-projective dependency CRF.</p>
<p>For references see:</p>
<ul class="simple">
<li><p>Non-projective dependency parsing using spanning tree algorithms <span id="id4">[<a class="reference internal" href="refs.html#id6" title="Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajič. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, 523–530. Association for Computational Linguistics, 2005.">MPRHajivc05</a>]</span></p></li>
<li><p>Structured prediction models via the matrix-tree theorem <span id="id5">[<a class="reference internal" href="refs.html#id5" title="Terry Koo, Amir Globerson, Xavier Carreras Pérez, and Michael Collins. Structured prediction models via the matrix-tree theorem. In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), 141–150. 2007.">KGCPerezC07</a>]</span></p></li>
</ul>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>log_potentials</strong> (<em>tensor</em>) – event shape (<em>N x N</em>) head, child  with
arc scores with root scores on diagonal e.g.
<span class="math notranslate nohighlight">\(\phi(i, j)\)</span> where <span class="math notranslate nohighlight">\(\phi(i, i)\)</span> is (root, i).</p>
</dd>
</dl>
<p>Compact representation: N long tensor in [0, .. N] (indexing is +1)</p>
<p>Note: Does not currently implement argmax (Chiu-Liu) or sampling.</p>
</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
<span class="k">def</span> <span class="nf">show_deps</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">NonProjectiveDependencyCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_deps</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_28_0.png" src="_images/model_28_0.png" />
</div>
</div>
</section>
<section id="Binary-Labeled-Tree">
<h2>Binary Labeled Tree<a class="headerlink" href="#Binary-Labeled-Tree" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="py class">
<dt class="sig sig-object py" id="torch_struct.TreeCRF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">TreeCRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#TreeCRF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.TreeCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents a 0th-order span parser with NT nonterminals. Implemented using a
fast CKY algorithm.</p>
<p>For example usage see:</p>
<ul class="simple">
<li><p>A Minimal Span-Based Neural Constituency Parser <span id="id6">[<a class="reference internal" href="refs.html#id10" title="Mitchell Stern, Jacob Andreas, and Dan Klein. A minimal span-based neural constituency parser. arXiv preprint arXiv:1705.03919, 2017.">SAK17</a>]</span></p></li>
</ul>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tensor</em>) – event_shape (<em>N x N x NT</em>), e.g.
<span class="math notranslate nohighlight">\(\phi(i, j, nt)\)</span></p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Implementation uses width-batched, forward-pass only</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(N)\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O(N^2)\)</span></p></li>
</ul>
<p>Compact representation:  <em>N x N x NT</em> long tensor (Same)</p>
</dd></dl>

</div></blockquote>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">NT</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">3</span>
<span class="k">def</span> <span class="nf">show_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">t</span><span class="p">[</span> <span class="p">:,</span> <span class="p">:</span> <span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
               <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">[</span> <span class="p">:,:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
               <span class="mi">3</span> <span class="o">*</span> <span class="n">t</span><span class="p">[</span> <span class="p">:,:,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">NT</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">TreeCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">)</span>
<span class="n">show_tree</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_31_0.png" src="_images/model_31_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_tree</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_32_0.png" src="_images/model_32_0.png" />
</div>
</div>
</section>
<section id="Probabilistic-Context-Free-Grammar">
<h2>Probabilistic Context-Free Grammar<a class="headerlink" href="#Probabilistic-Context-Free-Grammar" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="py class">
<dt class="sig sig-object py" id="torch_struct.SentCFG">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">SentCFG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#SentCFG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.SentCFG" title="Permalink to this definition">¶</a></dt>
<dd><p>Represents a full generative context-free grammar with
non-terminals NT and terminals T.</p>
<p>Event shape is of the form:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tuple</em>) – event tuple with event shapes
terms (<em>N x T</em>)
rules (<em>NT x (NT+T) x (NT+T)</em>)
root  (<em>NT</em>)</p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em>) – batch shape integers for length masking.</p></li>
</ul>
</dd>
</dl>
<p>Implementation uses width-batched, forward-pass only</p>
<ul class="simple">
<li><p>Parallel Time: <span class="math notranslate nohighlight">\(O(N)\)</span> parallel merges.</p></li>
<li><p>Forward Memory: <span class="math notranslate nohighlight">\(O(N^2 (NT+T))\)</span></p></li>
</ul>
<p>Compact representation:  (<em>N x N x NT</em>) long tensor</p>
</dd></dl>

</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">NT</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span>
<span class="k">def</span> <span class="nf">show_prob_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">t</span><span class="p">[</span> <span class="p">:,</span> <span class="p">:</span> <span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
               <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">[</span> <span class="p">:,:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
               <span class="mi">3</span> <span class="o">*</span> <span class="n">t</span><span class="p">[</span> <span class="p">:,:,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">terminals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
<span class="n">rules</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">NT</span><span class="p">,</span> <span class="n">NT</span><span class="o">+</span><span class="n">T</span><span class="p">,</span>  <span class="n">NT</span><span class="o">+</span><span class="n">T</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">NT</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">SentCFG</span><span class="p">((</span><span class="n">terminals</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">init</span><span class="p">))</span>
<span class="n">term</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">argmax</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Rules</span>
<span class="n">show_prob_tree</span><span class="p">(</span><span class="n">rules</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_36_0.png" src="_images/model_36_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Terminals</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">term</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.image.AxesImage at 0x7f1877a1fb70&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_37_1.png" src="_images/model_37_1.png" />
</div>
</div>
</section>
<section id="Autoregressive-/-Beam-Search">
<h2>Autoregressive / Beam Search<a class="headerlink" href="#Autoregressive-/-Beam-Search" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="py class">
<dt class="sig sig-object py" id="torch_struct.Autoregressive">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">Autoregressive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive" title="Permalink to this definition">¶</a></dt>
<dd><p>Autoregressive sequence model utilizing beam search.</p>
<ul class="simple">
<li><p>batch_shape -&gt; Given by initializer</p></li>
<li><p>event_shape -&gt; N x T sequence of choices</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#torch_struct.AutoregressiveModel" title="torch_struct.AutoregressiveModel"><em>AutoregressiveModel</em></a>) – A lazily computed autoregressive model.</p></li>
<li><p><strong>init</strong> (<em>tuple of tensors</em><em>, </em><em>batch_shape x </em><em>…</em>) – initial state of autoregressive model.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em>) – number of classes in each time step</p></li>
<li><p><strong>n_length</strong> (<em>int</em>) – max length of sequence</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.Autoregressive.beam_topk">
<span class="sig-name descname"><span class="pre">beam_topk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">K</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive.beam_topk"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive.beam_topk" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute “top-k” using beam search</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>K</strong> – top-k</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>paths (<em>K x batch x N x C</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.Autoregressive.greedy_max">
<span class="sig-name descname"><span class="pre">greedy_max</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive.greedy_max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive.greedy_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute “argmax” using greedy search.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>greedy_path (<em>batch x N x C</em>)
greedy_max (<em>batch</em>)
logits (<em>batch x N x C</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.Autoregressive.greedy_tempmax">
<span class="sig-name descname"><span class="pre">greedy_tempmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive.greedy_tempmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive.greedy_tempmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute differentiable scheduled sampling using greedy search.</p>
<p>Based on:</p>
<ul class="simple">
<li><p>Differentiable Scheduled Sampling for Credit Assignment <span id="id7">[<a class="reference internal" href="refs.html#id16" title="Kartik Goyal, Chris Dyer, and Taylor Berg-Kirkpatrick. Differentiable scheduled sampling for credit assignment. arXiv preprint arXiv:1704.06970, 2017.">GDBK17</a>]</span></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alpha</strong> – alpha param</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>greedy_path (<em>batch x N x C</em>)
greedy_max (<em>batch</em>)
logits (<em>batch x N x C</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.Autoregressive.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute structured samples from the distribution <span class="math notranslate nohighlight">\(z \sim p(z)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sample_shape</strong> (<em>torch.Size</em>) – number of samples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>samples (<em>sample_shape x batch_shape x event_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.Autoregressive.sample_without_replacement">
<span class="sig-name descname"><span class="pre">sample_without_replacement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#Autoregressive.sample_without_replacement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.Autoregressive.sample_without_replacement" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute sampling without replacement using Gumbel trick.</p>
<p>Based on:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for</dt><dd><p>Sampling Sequences Without Replacement <span id="id8">[<a class="reference internal" href="refs.html#id15" title="Wouter Kool, Herke van Hoof, and Max Welling. Stochastic beams and where to find them: the gumbel-top-k trick for sampling sequences without replacement. CoRR, 2019. URL: http://arxiv.org/abs/1903.06059, arXiv:1903.06059.">KvHW19</a>]</span></p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sample_shape</strong> (<em>torch.Size</em>) – batch_size</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>paths (<em>K x batch x N x C</em>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.AutoregressiveModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">AutoregressiveModel</span></span><a class="reference internal" href="_modules/torch_struct/autoregressive.html#AutoregressiveModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.AutoregressiveModel" title="Permalink to this definition">¶</a></dt>
<dd><p>User should implement as their favorite RNN / Transformer / etc.</p>
</dd></dl>

</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">layer</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">init</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">H</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">t</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">a</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">show_ar</span><span class="p">(</span><span class="n">chain</span><span class="p">):</span>
     <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">RNN_AR</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sparse</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="ow">and</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">t</span><span class="p">(</span><span class="n">state</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">t</span><span class="p">((</span><span class="n">state</span><span class="p">,))</span>


<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">Autoregressive</span><span class="p">(</span><span class="n">RNN_AR</span><span class="p">(),</span> <span class="n">init</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">path</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">greedy_max</span><span class="p">()</span>
<span class="n">show_ar</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(-11.7909, grad_fn=&lt;SelectBackward&gt;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_41_1.png" src="_images/model_41_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[-11.7909, -11.8150, -11.7972]], grad_fn=&lt;ViewBackward&gt;)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">out</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">beam_topk</span><span class="p">(</span><span class="mi">5</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">show_ar</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_43_0.png" src="_images/model_43_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_43_1.png" src="_images/model_43_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_43_2.png" src="_images/model_43_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">out</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,))[:,</span> <span class="mi">0</span> <span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">show_ar</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([5, 10, 4])
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_44_1.png" src="_images/model_44_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_44_2.png" src="_images/model_44_2.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_44_3.png" src="_images/model_44_3.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">out</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample_without_replacement</span><span class="p">((</span><span class="mi">5</span><span class="p">,))[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">show_ar</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_45_0.png" src="_images/model_45_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_45_1.png" src="_images/model_45_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_45_2.png" src="_images/model_45_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">Autoregressive</span><span class="p">(</span><span class="n">RNN_AR</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">init</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">greedy_tempmax</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">show_ar</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
<span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_46_0.png" src="_images/model_46_0.png" />
</div>
</div>
</section>
<section id="Base-Class">
<h2>Base Class<a class="headerlink" href="#Base-Class" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_struct.StructDistribution">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">torch_struct.</span></span><span class="sig-name descname"><span class="pre">StructDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_potentials</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Base structured distribution class.</p>
<p>Dynamic distribution for length N of structures <span class="math notranslate nohighlight">\(p(z)\)</span>.</p>
<p>Implemented based on gradient identities from:</p>
<ul class="simple">
<li><p>Inside-outside and forward-backward algorithms are just backprop <span id="id9">[<a class="reference internal" href="refs.html#id7" title="Jason Eisner. Inside-outside and forward-backward algorithms are just backprop (tutorial paper). In Proceedings of the Workshop on Structured Prediction for NLP, 1–17. 2016.">Eis16</a>]</span></p></li>
<li><p>Semiring Parsing <span id="id10">[<a class="reference internal" href="refs.html#id8" title="Joshua Goodman. Semiring parsing. Computational Linguistics, 25(4):573–605, 1999.">Goo99</a>]</span></p></li>
<li><p>First-and second-order expectation semirings with applications to minimum-risk training on translation forests <span id="id11">[<a class="reference internal" href="refs.html#id9" title="Zhifei Li and Jason Eisner. First-and second-order expectation semirings with applications to minimum-risk training on translation forests. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, 40–51. Association for Computational Linguistics, 2009.">LE09</a>]</span></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_potentials</strong> (<em>tensor</em><em>, </em><em>batch_shape x event_shape</em>) – log-potentials <span class="math notranslate nohighlight">\(\phi\)</span></p></li>
<li><p><strong>lengths</strong> (<em>long tensor</em><em>, </em><em>batch_shape</em>) – integers for length masking</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.argmax">
<span class="sig-name descname"><span class="pre">argmax</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.argmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute an argmax for distribution <span class="math notranslate nohighlight">\(\arg\max p(z)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>argmax (<em>batch_shape x event_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.count">
<span class="sig-name descname"><span class="pre">count</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.count"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.count" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log-partition function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.cross_entropy">
<span class="sig-name descname"><span class="pre">cross_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.cross_entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.cross_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cross-entropy for distribution p(self) and q(other) <span class="math notranslate nohighlight">\(H[p, q]\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – Comparison distribution</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>cross entropy (<em>batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute entropy for distribution <span class="math notranslate nohighlight">\(H[z]\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>entropy (<em>batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.from_event">
<span class="sig-name descname"><span class="pre">from_event</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">event</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.from_event"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.from_event" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert event to simple representation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.kl">
<span class="sig-name descname"><span class="pre">kl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.kl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.kl" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute KL-divergence for distribution p(self) and q(other) <span class="math notranslate nohighlight">\(KL[p || q] = H[p, q] - H[p]\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> – Comparison distribution</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>cross entropy (<em>batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.kmax">
<span class="sig-name descname"><span class="pre">kmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.kmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.kmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the k-max for distribution <span class="math notranslate nohighlight">\(k\max p(z)\)</span>.</p>
<dl class="simple">
<dt>Parameters :</dt><dd><p>k : Number of solutions to return</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>kmax (<em>k x batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute log probability over values <span class="math notranslate nohighlight">\(p(z)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> (<em>tensor</em>) – One-hot events (<em>sample_shape x batch_shape x event_shape</em>)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log_probs (<em>sample_shape x batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.marginals">
<span class="sig-name descname"><span class="pre">marginals</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.marginals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.marginals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute marginals for distribution <span class="math notranslate nohighlight">\(p(z_t)\)</span>.</p>
<p>Can be used in higher-order calculations, i.e.</p>
<ul class="simple">
<li></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>marginals (<em>batch_shape x event_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute an max for distribution <span class="math notranslate nohighlight">\(\max p(z)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>max (<em>batch_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.partition">
<span class="sig-name descname"><span class="pre">partition</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.partition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.partition" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log-partition function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute structured samples from the distribution <span class="math notranslate nohighlight">\(z \sim p(z)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sample_shape</strong> (<em>int</em>) – number of samples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>samples (<em>sample_shape x batch_shape x event_shape</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.to_event">
<span class="sig-name descname"><span class="pre">to_event</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.to_event"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.to_event" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert simple representation to event.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_struct.StructDistribution.topk">
<span class="sig-name descname"><span class="pre">topk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch_struct/distributions.html#StructDistribution.topk"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_struct.StructDistribution.topk" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the k-argmax for distribution <span class="math notranslate nohighlight">\(k\max p(z)\)</span>.</p>
<dl class="simple">
<dt>Parameters :</dt><dd><p>k : Number of solutions to return</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>kmax (<em>k x batch_shape x event_shape</em>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span>

<span class="c1"># batch, N, z_n, z_n_1</span>
<span class="n">log_potentials</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">torch_struct</span><span class="o">.</span><span class="n">LinearChainCRF</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">argmax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_49_0.png" src="_images/model_49_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_49_1.png" src="_images/model_49_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">show_chain</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">marginals</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_50_0.png" src="_images/model_50_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_50_1.png" src="_images/model_50_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">show_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
    <span class="n">show_chain</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">show_chain</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">show_chain</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_samples</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,)))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_52_0.png" src="_images/model_52_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_52_1.png" src="_images/model_52_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_52_2.png" src="_images/model_52_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">show_samples</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_53_0.png" src="_images/model_53_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_53_1.png" src="_images/model_53_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_53_2.png" src="_images/model_53_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Enumerate</span>
<span class="n">x</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">enumerate_support</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">show_chain</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([256, 3, 7, 2, 2])
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_1.png" src="_images/model_54_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_2.png" src="_images/model_54_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_3.png" src="_images/model_54_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_4.png" src="_images/model_54_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_5.png" src="_images/model_54_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_6.png" src="_images/model_54_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_7.png" src="_images/model_54_7.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_8.png" src="_images/model_54_8.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_9.png" src="_images/model_54_9.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_54_10.png" src="_images/model_54_10.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.image.AxesImage at 0x7f1877c52c18&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/model_55_1.png" src="_images/model_55_1.png" />
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="README.html" class="btn btn-neutral float-left" title="Torch-Struct: Structured Prediction Library" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="networks.html" class="btn btn-neutral float-right" title="Networks and Data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Sasha Rush.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>