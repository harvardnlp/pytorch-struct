<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>torch_struct.distributions &mdash; pytorch-struct 0.4 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> pytorch-struct
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Torch-Struct: Structured Prediction Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../networks.html">Networks and Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../semiring.html">Advanced: Semirings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pytorch-struct</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>torch_struct.distributions</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for torch_struct.distributions</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">constraints</span>
<span class="kn">from</span> <span class="nn">torch.distributions.distribution</span> <span class="kn">import</span> <span class="n">Distribution</span>
<span class="kn">from</span> <span class="nn">torch.distributions.utils</span> <span class="kn">import</span> <span class="n">lazy_property</span>
<span class="kn">from</span> <span class="nn">.linearchain</span> <span class="kn">import</span> <span class="n">LinearChain</span>
<span class="kn">from</span> <span class="nn">.cky</span> <span class="kn">import</span> <span class="n">CKY</span>
<span class="kn">from</span> <span class="nn">.semimarkov</span> <span class="kn">import</span> <span class="n">SemiMarkov</span>
<span class="kn">from</span> <span class="nn">.alignment</span> <span class="kn">import</span> <span class="n">Alignment</span>
<span class="kn">from</span> <span class="nn">.deptree</span> <span class="kn">import</span> <span class="n">DepTree</span><span class="p">,</span> <span class="n">deptree_nonproj</span><span class="p">,</span> <span class="n">deptree_part</span>
<span class="kn">from</span> <span class="nn">.cky_crf</span> <span class="kn">import</span> <span class="n">CKY_CRF</span>
<span class="kn">from</span> <span class="nn">.semirings</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LogSemiring</span><span class="p">,</span>
    <span class="n">MaxSemiring</span><span class="p">,</span>
    <span class="n">EntropySemiring</span><span class="p">,</span>
    <span class="n">CrossEntropySemiring</span><span class="p">,</span>
    <span class="n">KLDivergenceSemiring</span><span class="p">,</span>
    <span class="n">MultiSampledSemiring</span><span class="p">,</span>
    <span class="n">KMaxSemiring</span><span class="p">,</span>
    <span class="n">StdSemiring</span><span class="p">,</span>
    <span class="n">GumbelCRFSemiring</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="StructDistribution"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution">[docs]</a><span class="k">class</span> <span class="nc">StructDistribution</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base structured distribution class.</span>

<span class="sd">    Dynamic distribution for length N of structures :math:`p(z)`.</span>

<span class="sd">    Implemented based on gradient identities from:</span>

<span class="sd">    * Inside-outside and forward-backward algorithms are just backprop :cite:`eisner2016inside`</span>
<span class="sd">    * Semiring Parsing :cite:`goodman1999semiring`</span>
<span class="sd">    * First-and second-order expectation semirings with applications to minimum-risk training on translation forests :cite:`li2009first`</span>

<span class="sd">    Parameters:</span>
<span class="sd">        log_potentials (tensor, batch_shape x event_shape) :  log-potentials :math:`\phi`</span>
<span class="sd">        lengths (long tensor, batch_shape) : integers for length masking</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arg_constraints</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;log_potentials&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
        <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">nonnegative_integer</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{},</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">log_potentials</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">event_shape</span> <span class="o">=</span> <span class="n">log_potentials</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span> <span class="o">=</span> <span class="n">log_potentials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_new</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="StructDistribution.log_prob"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute log probability over values :math:`p(z)`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            value (tensor): One-hot events (*sample_shape x batch_shape x event_shape*)</span>

<span class="sd">        Returns:</span>
<span class="sd">            log_probs (*sample_shape x batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">d</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="n">batch_dims</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">event_shape</span><span class="p">))</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">()</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span>
            <span class="n">value</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">),</span>
            <span class="n">batch_dims</span><span class="o">=</span><span class="n">batch_dims</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">v</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">partition</span></div>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute entropy for distribution :math:`H[z]`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            entropy (*batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">EntropySemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

<div class="viewcode-block" id="StructDistribution.cross_entropy"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.cross_entropy">[docs]</a>    <span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cross-entropy for distribution p(self) and q(other) :math:`H[p, q]`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            other : Comparison distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">            cross entropy (*batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">CrossEntropySemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="StructDistribution.kl"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute KL-divergence for distribution p(self) and q(other) :math:`KL[p || q] = H[p, q] - H[p]`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            other : Comparison distribution</span>

<span class="sd">        Returns:</span>
<span class="sd">            cross entropy (*batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">KLDivergenceSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span>
        <span class="p">)</span></div>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute an max for distribution :math:`\max p(z)`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            max (*batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">MaxSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute an argmax for distribution :math:`\arg\max p(z)`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            argmax (*batch_shape x event_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">MaxSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">marginals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

<div class="viewcode-block" id="StructDistribution.kmax"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.kmax">[docs]</a>    <span class="k">def</span> <span class="nf">kmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the k-max for distribution :math:`k\max p(z)`.</span>

<span class="sd">        Parameters :</span>
<span class="sd">            k : Number of solutions to return</span>

<span class="sd">        Returns:</span>
<span class="sd">            kmax (*k x batch_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">KMaxSemiring</span><span class="p">(</span><span class="n">k</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">,</span> <span class="n">_raw</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="StructDistribution.topk"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.topk">[docs]</a>    <span class="k">def</span> <span class="nf">topk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the k-argmax for distribution :math:`k\max p(z)`.</span>

<span class="sd">        Parameters :</span>
<span class="sd">            k : Number of solutions to return</span>

<span class="sd">        Returns:</span>
<span class="sd">            kmax (*k x batch_shape x event_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">KMaxSemiring</span><span class="p">(</span><span class="n">k</span><span class="p">))</span><span class="o">.</span><span class="n">marginals</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">,</span> <span class="n">_raw</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span></div>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">argmax</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">marginals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute marginals for distribution :math:`p(z_t)`.</span>

<span class="sd">        Can be used in higher-order calculations, i.e.</span>

<span class="sd">        *</span>

<span class="sd">        Returns:</span>
<span class="sd">            marginals (*batch_shape x event_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">LogSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">marginals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Compute the log-partition function.&quot;</span>
        <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">)</span>
        <span class="n">ones</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">StdSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">gumbel_crf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="n">st_gumbel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">GumbelCRFSemiring</span><span class="p">(</span><span class="n">temperature</span><span class="p">))</span><span class="o">.</span><span class="n">marginals</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">st_gumbel</span>

    <span class="c1"># @constraints.dependent_property</span>
    <span class="c1"># def support(self):</span>
    <span class="c1">#     pass</span>

    <span class="c1"># @property</span>
    <span class="c1"># def param_shape(self):</span>
    <span class="c1">#     return self._param.size()</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">partition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Compute the log-partition function.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">LogSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

<div class="viewcode-block" id="StructDistribution.sample"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">()):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute structured samples from the distribution :math:`z \sim p(z)`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            sample_shape (int): number of samples</span>

<span class="sd">        Returns:</span>
<span class="sd">            samples (*sample_shape x batch_shape x event_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">nsamples</span> <span class="o">=</span> <span class="n">sample_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_struct</span><span class="p">(</span><span class="n">MultiSampledSemiring</span><span class="p">)</span><span class="o">.</span><span class="n">marginals</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lengths</span>
                <span class="p">)</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">tmp_sample</span> <span class="o">=</span> <span class="n">MultiSampledSemiring</span><span class="o">.</span><span class="n">to_discrete</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_sample</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span></div>

<div class="viewcode-block" id="StructDistribution.to_event"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.to_event">[docs]</a>    <span class="k">def</span> <span class="nf">to_event</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">extra</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="s2">&quot;Convert simple representation to event.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">to_parts</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">extra</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="n">lengths</span><span class="p">)</span></div>

<div class="viewcode-block" id="StructDistribution.from_event"><a class="viewcode-back" href="../../model.html#torch_struct.StructDistribution.from_event">[docs]</a>    <span class="k">def</span> <span class="nf">from_event</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">event</span><span class="p">):</span>
        <span class="s2">&quot;Convert event to simple representation.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">from_parts</span><span class="p">(</span><span class="n">event</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_struct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">struct</span><span class="p">(</span><span class="n">sr</span> <span class="k">if</span> <span class="n">sr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">LogSemiring</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearChainCRF"><a class="viewcode-back" href="../../model.html#torch_struct.LinearChainCRF">[docs]</a><span class="k">class</span> <span class="nc">LinearChainCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents structured linear-chain CRFs with C classes.</span>

<span class="sd">    For reference see:</span>

<span class="sd">    * An introduction to conditional random fields :cite:`sutton2012introduction`</span>

<span class="sd">    Example application:</span>

<span class="sd">    * Bidirectional LSTM-CRF Models for Sequence Tagging :cite:`huang2015bidirectional`</span>


<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">        log_potentials (tensor) : event shape (*(N-1) x C x C*) e.g.</span>
<span class="sd">                                  :math:`\phi(n,  z_{n+1}, z_{n})`</span>
<span class="sd">        lengths (long tensor) : batch_shape integers for length masking.</span>


<span class="sd">    Compact representation: N long tensor in [0, ..., C-1]</span>

<span class="sd">    Implementation uses linear-scan, forward-pass only.</span>

<span class="sd">    * Parallel Time: :math:`O(\log(N))` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O(N \log(N) C^2)`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">struct</span> <span class="o">=</span> <span class="n">LinearChain</span></div>


<div class="viewcode-block" id="AlignmentCRF"><a class="viewcode-back" href="../../model.html#torch_struct.AlignmentCRF">[docs]</a><span class="k">class</span> <span class="nc">AlignmentCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents basic alignment algorithm, i.e. dynamic-time warping, Needleman-Wunsch, and Smith-Waterman.</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">        log_potentials (tensor) : event_shape (*N x M x 3*), e.g.</span>
<span class="sd">                                    :math:`\phi(i, j, op)`</span>
<span class="sd">                                  Ops are 0 -&gt; j-1, 1-&gt;i-1,j-1, and 2-&gt;i-1</span>
<span class="sd">        local (bool): if true computes local alignment (Smith-Waterman), else Needleman-Wunsch</span>
<span class="sd">        max_gap (int or None): the maximum gap to allow in the dynamic program</span>
<span class="sd">        lengths (long tensor) : batch shape integers for length masking.</span>


<span class="sd">    Implementation uses convolution and linear-scan. Use max_gap for long sequences.</span>

<span class="sd">    * Parallel Time: :math:`O(\log (M + N))` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O((M+N)^2)`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">struct</span> <span class="o">=</span> <span class="n">Alignment</span>
    <span class="n">arg_constraints</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;log_potentials&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span><span class="p">,</span>
        <span class="s2">&quot;local&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">boolean</span><span class="p">,</span>
        <span class="s2">&quot;max_gap&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">nonnegative_integer</span><span class="p">,</span>
        <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">nonnegative_integer</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_potentials</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_gap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local</span> <span class="o">=</span> <span class="n">local</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_gap</span> <span class="o">=</span> <span class="n">max_gap</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_struct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">struct</span><span class="p">(</span>
            <span class="n">sr</span> <span class="k">if</span> <span class="n">sr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">LogSemiring</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local</span><span class="p">,</span> <span class="n">max_gap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_gap</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="HMM"><a class="viewcode-back" href="../../model.html#torch_struct.HMM">[docs]</a><span class="k">class</span> <span class="nc">HMM</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents hidden-markov smoothing with C hidden states.</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">        transition (tensor): log-probabilities (*C X C*) :math:`p(z_n| z_n-1)`</span>
<span class="sd">        emission (tensor): log-probabilities (*V x C*)  :math:`p(x_n| z_n)`</span>
<span class="sd">        init (tensor): log-probabilities (*C*) :math:`p(z_1)`</span>
<span class="sd">        observations (long tensor): indices (*batch x N*) between [0, V-1]</span>

<span class="sd">    Compact representation: N long tensor in [0, ..., C-1]</span>

<span class="sd">    Implemented as a special case of linear chain CRF.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transition</span><span class="p">,</span> <span class="n">emission</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">log_potentials</span> <span class="o">=</span> <span class="n">HMM</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">hmm</span><span class="p">(</span><span class="n">transition</span><span class="p">,</span> <span class="n">emission</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">observations</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>

    <span class="n">struct</span> <span class="o">=</span> <span class="n">LinearChain</span></div>


<div class="viewcode-block" id="SemiMarkovCRF"><a class="viewcode-back" href="../../model.html#torch_struct.SemiMarkovCRF">[docs]</a><span class="k">class</span> <span class="nc">SemiMarkovCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a semi-markov or segmental CRF with C classes of max width K</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">       log_potentials : event shape (*N x K x C x C*) e.g.</span>
<span class="sd">                        :math:`\phi(n, k, z_{n+1}, z_{n})`</span>
<span class="sd">       lengths (long tensor) : batch shape integers for length masking.</span>

<span class="sd">    Compact representation: N long tensor in [-1, 0, ..., C-1]</span>

<span class="sd">    Implementation uses linear-scan, forward-pass only.</span>

<span class="sd">    * Parallel Time: :math:`O(\log(N))` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O(N \log(N) C^2 K^2)`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">struct</span> <span class="o">=</span> <span class="n">SemiMarkov</span></div>


<div class="viewcode-block" id="DependencyCRF"><a class="viewcode-back" href="../../model.html#torch_struct.DependencyCRF">[docs]</a><span class="k">class</span> <span class="nc">DependencyCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a projective dependency CRF.</span>

<span class="sd">    Reference:</span>

<span class="sd">    * Bilexical grammars and their cubic-time parsing algorithms :cite:`eisner2000bilexical`</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">       log_potentials (tensor) : event shape (*N x N*) head, child or (*N x N x L*) head,</span>
<span class="sd">                                 child, labels with arc scores with root scores on diagonal</span>
<span class="sd">                                 e.g. :math:`\phi(i, j)` where :math:`\phi(i, i)` is (root, i).</span>
<span class="sd">       lengths (long tensor) : batch shape integers for length masking.</span>


<span class="sd">    Compact representation: N long tensor in [0, .. N] (indexing is +1)</span>

<span class="sd">    Implementation uses linear-scan, forward-pass only.</span>

<span class="sd">    * Parallel Time: :math:`O(N)` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O(N \log(N) C^2 K^2)`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{},</span> <span class="n">multiroot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DependencyCRF</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">struct</span> <span class="o">=</span> <span class="n">DepTree</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">struct</span><span class="p">,</span> <span class="s2">&quot;multiroot&quot;</span><span class="p">,</span> <span class="n">multiroot</span><span class="p">)</span></div>


<div class="viewcode-block" id="TreeCRF"><a class="viewcode-back" href="../../model.html#torch_struct.TreeCRF">[docs]</a><span class="k">class</span> <span class="nc">TreeCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a 0th-order span parser with NT nonterminals. Implemented using a</span>
<span class="sd">    fast CKY algorithm.</span>

<span class="sd">    For example usage see:</span>

<span class="sd">    * A Minimal Span-Based Neural Constituency Parser :cite:`stern2017minimal`</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">        log_potentials (tensor) : event_shape (*N x N x NT*), e.g.</span>
<span class="sd">                                    :math:`\phi(i, j, nt)`</span>
<span class="sd">        lengths (long tensor) : batch shape integers for length masking.</span>

<span class="sd">    Implementation uses width-batched, forward-pass only</span>

<span class="sd">    * Parallel Time: :math:`O(N)` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O(N^2)`</span>

<span class="sd">    Compact representation:  *N x N x NT* long tensor (Same)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">struct</span> <span class="o">=</span> <span class="n">CKY_CRF</span></div>


<div class="viewcode-block" id="SentCFG"><a class="viewcode-back" href="../../model.html#torch_struct.SentCFG">[docs]</a><span class="k">class</span> <span class="nc">SentCFG</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a full generative context-free grammar with</span>
<span class="sd">    non-terminals NT and terminals T.</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">        log_potentials (tuple) : event tuple with event shapes</span>
<span class="sd">                         terms (*N x T*)</span>
<span class="sd">                         rules (*NT x (NT+T) x (NT+T)*)</span>
<span class="sd">                         root  (*NT*)</span>
<span class="sd">        lengths (long tensor) : batch shape integers for length masking.</span>

<span class="sd">    Implementation uses width-batched, forward-pass only</span>

<span class="sd">    * Parallel Time: :math:`O(N)` parallel merges.</span>
<span class="sd">    * Forward Memory: :math:`O(N^2 (NT+T))`</span>

<span class="sd">    Compact representation:  (*N x N x NT*) long tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">struct</span> <span class="o">=</span> <span class="n">CKY</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">log_potentials</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">event_shape</span> <span class="o">=</span> <span class="n">log_potentials</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span> <span class="o">=</span> <span class="n">log_potentials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">event_shape</span><span class="o">=</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NonProjectiveDependencyCRF"><a class="viewcode-back" href="../../model.html#torch_struct.NonProjectiveDependencyCRF">[docs]</a><span class="k">class</span> <span class="nc">NonProjectiveDependencyCRF</span><span class="p">(</span><span class="n">StructDistribution</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a non-projective dependency CRF.</span>

<span class="sd">    For references see:</span>

<span class="sd">    * Non-projective dependency parsing using spanning tree algorithms :cite:`mcdonald2005non`</span>
<span class="sd">    * Structured prediction models via the matrix-tree theorem :cite:`koo2007structured`</span>

<span class="sd">    Event shape is of the form:</span>

<span class="sd">    Parameters:</span>
<span class="sd">       log_potentials (tensor) : event shape (*N x N*) head, child  with</span>
<span class="sd">                                 arc scores with root scores on diagonal e.g.</span>
<span class="sd">                                 :math:`\phi(i, j)` where :math:`\phi(i, i)` is (root, i).</span>

<span class="sd">    Compact representation: N long tensor in [0, .. N] (indexing is +1)</span>

<span class="sd">    Note: Does not currently implement argmax (Chiu-Liu) or sampling.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">arg_constraints</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;log_potentials&quot;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{},</span> <span class="n">multiroot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NonProjectiveDependencyCRF</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">log_potentials</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiroot</span> <span class="o">=</span> <span class="n">multiroot</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">marginals</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute marginals for distribution :math:`p(z_t)`.</span>

<span class="sd">        Algorithm is :math:`O(N^3)` but very fast on batched GPU.</span>

<span class="sd">        Returns:</span>
<span class="sd">            marginals (*batch_shape x event_shape*)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">deptree_nonproj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiroot</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">partition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the partition function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">deptree_part</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_potentials</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiroot</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lengths</span><span class="p">)</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use Chiu-Liu Algorithm. :math:`O(N^2)`</span>

<span class="sd">        (Currently not implemented)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@lazy_property</span>
    <span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Sasha Rush.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>